# Transformer from Scratch

A PyTorch implementation of the original "Attention Is All You Need" Transformer architecture. This project demonstrates a complete Transformer model built from low-level components, closely following the seminal paper.

---

## To run training
```bash
python train.py
```
## To use the translator app
```bash
python app.py
```
